#!/usr/bin/env python3
"""
å…³å¡éªŒè¯è„šæœ¬

æ¨¡æ‹Ÿå‰ç«¯åŠ è½½å…³å¡å¹¶è§£ç­”ï¼Œç”ŸæˆéªŒè¯æŠ¥å‘Šã€‚

åŠŸèƒ½ï¼š
1. åŠ è½½æ¯ä¸ªå…³å¡çš„JSONæ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿå‰ç«¯fetchï¼‰
2. éªŒè¯å…³å¡æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®
3. æ¨¡æ‹Ÿè§£ç­”å…³å¡ï¼ˆéªŒè¯å…³å¡æ˜¯å¦å¯è§£ï¼‰
4. ç”Ÿæˆè¯¦ç»†çš„éªŒè¯æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    python validate_levels.py --all          # éªŒè¯æ‰€æœ‰è¯åº“
    python validate_levels.py -g grade3_1    # éªŒè¯æŒ‡å®šè¯åº“
    python validate_levels.py -g gre --limit 10  # åªéªŒè¯å‰10å…³
    python validate_levels.py --report       # ç”ŸæˆHTMLæŠ¥å‘Š
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum


class ValidationStatus(Enum):
    """éªŒè¯çŠ¶æ€"""
    SUCCESS = "success"      # éªŒè¯é€šè¿‡
    LOAD_FAILED = "load_failed"  # åŠ è½½å¤±è´¥
    FORMAT_ERROR = "format_error"  # æ ¼å¼é”™è¯¯
    SOLVE_FAILED = "solve_failed"  # æ— æ³•è§£ç­”
    PARTIAL = "partial"      # éƒ¨åˆ†é€šè¿‡


@dataclass
class LevelValidation:
    """å•ä¸ªå…³å¡çš„éªŒè¯ç»“æœ"""
    group: str
    level: int
    status: ValidationStatus
    load_time_ms: float = 0
    solve_time_ms: float = 0
    grid_size: int = 0
    word_count: int = 0
    words: List[str] = field(default_factory=list)
    prefilled_count: int = 0
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    solved_words: List[str] = field(default_factory=list)
    unsolved_words: List[str] = field(default_factory=list)


@dataclass  
class GroupValidation:
    """è¯åº“éªŒè¯ç»“æœ"""
    group_code: str
    group_name: str
    total_levels: int
    validated_levels: int
    success_count: int
    failed_count: int
    error_details: List[LevelValidation] = field(default_factory=list)
    all_results: List[LevelValidation] = field(default_factory=list)
    total_load_time_ms: float = 0
    total_solve_time_ms: float = 0


class LevelValidator:
    """å…³å¡éªŒè¯å™¨"""
    
    def __init__(self, levels_dir: Path = None):
        """åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            levels_dir: å…³å¡æ•°æ®ç›®å½•ï¼Œé»˜è®¤ä¸º src/data/levels
        """
        if levels_dir is None:
            levels_dir = Path(__file__).parent.parent / "data" / "levels"
        self.levels_dir = levels_dir
        self.reports_dir = Path(__file__).parent.parent / "data" / "validation_reports"
        self.reports_dir.mkdir(parents=True, exist_ok=True)
    
    def load_level(self, group: str, level: int) -> Tuple[Optional[dict], float, Optional[str]]:
        """åŠ è½½å…³å¡æ•°æ®ï¼ˆæ¨¡æ‹Ÿå‰ç«¯fetchï¼‰
        
        Returns:
            (data, load_time_ms, error_message)
        """
        level_path = self.levels_dir / group / f"{level}.json"
        
        start = time.time()
        try:
            if not level_path.exists():
                return None, 0, f"æ–‡ä»¶ä¸å­˜åœ¨: {level_path}"
            
            with open(level_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            load_time = (time.time() - start) * 1000
            return data, load_time, None
            
        except json.JSONDecodeError as e:
            return None, 0, f"JSONè§£æé”™è¯¯: {e}"
        except Exception as e:
            return None, 0, f"åŠ è½½é”™è¯¯: {e}"
    
    def validate_format(self, data: dict) -> List[str]:
        """éªŒè¯å…³å¡æ•°æ®æ ¼å¼
        
        Returns:
            é”™è¯¯åˆ—è¡¨
        """
        errors = []
        
        # å¿…éœ€å­—æ®µ
        required_fields = ["grid_size", "cells", "words"]
        for field in required_fields:
            if field not in data:
                errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        if errors:
            return errors
        
        # éªŒè¯grid_size
        grid_size = data.get("grid_size", 0)
        if not isinstance(grid_size, int) or grid_size < 4 or grid_size > 15:
            errors.append(f"grid_sizeæ— æ•ˆ: {grid_size}")
        
        # éªŒè¯cells
        cells = data.get("cells", [])
        if not isinstance(cells, list) or len(cells) != grid_size:
            errors.append(f"cellsè¡Œæ•°é”™è¯¯: æœŸæœ›{grid_size}, å®é™…{len(cells) if isinstance(cells, list) else 'N/A'}")
        else:
            for row_idx, row in enumerate(cells):
                if not isinstance(row, list) or len(row) != grid_size:
                    errors.append(f"cellsç¬¬{row_idx}è¡Œåˆ—æ•°é”™è¯¯")
        
        # éªŒè¯words
        words = data.get("words", [])
        if not isinstance(words, list) or len(words) < 2:
            errors.append(f"wordsæ•°é‡ä¸è¶³: {len(words) if isinstance(words, list) else 'N/A'}")
        else:
            for idx, word in enumerate(words):
                if not isinstance(word, dict):
                    errors.append(f"ç¬¬{idx}ä¸ªå•è¯æ ¼å¼é”™è¯¯")
                    continue
                
                # éªŒè¯å•è¯å¿…éœ€å­—æ®µ
                word_required = ["word", "direction", "start_row", "start_col"]
                for field in word_required:
                    if field not in word:
                        errors.append(f"å•è¯{idx}ç¼ºå°‘å­—æ®µ: {field}")
                
                # éªŒè¯å•è¯åªåŒ…å«å­—æ¯
                word_text = word.get("word", "")
                if word_text and not word_text.isalpha():
                    errors.append(f"å•è¯åŒ…å«éå­—æ¯å­—ç¬¦: {word_text}")
                
                # éªŒè¯æ–¹å‘
                direction = word.get("direction", "")
                if direction not in ["across", "down"]:
                    errors.append(f"å•è¯{idx}æ–¹å‘æ— æ•ˆ: {direction}")
        
        return errors
    
    def solve_level(self, data: dict) -> Tuple[List[str], List[str], float]:
        """æ¨¡æ‹Ÿè§£ç­”å…³å¡
        
        æ£€æŸ¥æ¯ä¸ªå•è¯æ˜¯å¦å¯ä»¥æ­£ç¡®å¡«å…¥ç½‘æ ¼ï¼ˆä¸äº§ç”Ÿå†²çªï¼‰
        
        Returns:
            (solved_words, unsolved_words, solve_time_ms)
        """
        start = time.time()
        
        grid_size = data.get("grid_size", 0)
        cells = data.get("cells", [])
        words = data.get("words", [])
        prefilled = data.get("prefilled", {})
        
        # åˆ›å»ºæ¨¡æ‹Ÿç½‘æ ¼
        grid = [[None for _ in range(grid_size)] for _ in range(grid_size)]
        
        # å¡«å…¥é¢„å¡«å­—æ¯
        for key, letter in prefilled.items():
            try:
                row, col = map(int, key.split("-"))
                grid[row][col] = letter.upper()
            except:
                pass
        
        solved = []
        unsolved = []
        
        for word_info in words:
            word = word_info.get("word", "").upper()
            direction = word_info.get("direction", "across")
            start_row = word_info.get("start_row", 0)
            start_col = word_info.get("start_col", 0)
            length = len(word)
            
            can_solve = True
            conflicts = []
            
            # æ£€æŸ¥æ¯ä¸ªä½ç½®
            for i in range(length):
                if direction == "across":
                    r, c = start_row, start_col + i
                else:
                    r, c = start_row + i, start_col
                
                # è¾¹ç•Œæ£€æŸ¥
                if r < 0 or r >= grid_size or c < 0 or c >= grid_size:
                    can_solve = False
                    conflicts.append(f"ä½ç½®({r},{c})è¶…å‡ºè¾¹ç•Œ")
                    break
                
                # æ£€æŸ¥å•å…ƒæ ¼æ˜¯å¦å¯ç”¨
                cell_value = cells[r][c] if r < len(cells) and c < len(cells[r]) else None
                if cell_value is None:
                    can_solve = False
                    conflicts.append(f"ä½ç½®({r},{c})ä¸å¯ç”¨")
                    break
                
                # æ£€æŸ¥æ˜¯å¦ä¸ç°æœ‰å­—æ¯å†²çª
                expected_letter = word[i]
                existing = grid[r][c]
                if existing is not None and existing != expected_letter:
                    can_solve = False
                    conflicts.append(f"ä½ç½®({r},{c})å†²çª: æœŸæœ›{expected_letter}, ç°æœ‰{existing}")
            
            if can_solve:
                # å¡«å…¥å•è¯
                for i in range(length):
                    if direction == "across":
                        r, c = start_row, start_col + i
                    else:
                        r, c = start_row + i, start_col
                    grid[r][c] = word[i]
                solved.append(word)
            else:
                unsolved.append(f"{word}: {', '.join(conflicts)}")
        
        solve_time = (time.time() - start) * 1000
        return solved, unsolved, solve_time
    
    def validate_level(self, group: str, level: int) -> LevelValidation:
        """éªŒè¯å•ä¸ªå…³å¡"""
        result = LevelValidation(group=group, level=level, status=ValidationStatus.SUCCESS)
        
        # 1. åŠ è½½å…³å¡
        data, load_time, error = self.load_level(group, level)
        result.load_time_ms = load_time
        
        if error:
            result.status = ValidationStatus.LOAD_FAILED
            result.errors.append(error)
            return result
        
        # 2. éªŒè¯æ ¼å¼
        format_errors = self.validate_format(data)
        if format_errors:
            result.status = ValidationStatus.FORMAT_ERROR
            result.errors.extend(format_errors)
            return result
        
        # 3. æå–åŸºæœ¬ä¿¡æ¯
        result.grid_size = data.get("grid_size", 0)
        result.word_count = len(data.get("words", []))
        result.words = [w.get("word", "") for w in data.get("words", [])]
        result.prefilled_count = len(data.get("prefilled", {}))
        
        # 4. æ¨¡æ‹Ÿè§£ç­”
        solved, unsolved, solve_time = self.solve_level(data)
        result.solve_time_ms = solve_time
        result.solved_words = solved
        result.unsolved_words = unsolved
        
        if unsolved:
            result.status = ValidationStatus.SOLVE_FAILED
            result.errors.extend([f"æ— æ³•è§£ç­”: {u}" for u in unsolved])
        
        return result
    
    def validate_group(self, group_code: str, limit: int = None, verbose: bool = True) -> GroupValidation:
        """éªŒè¯æ•´ä¸ªè¯åº“"""
        # è¯»å–metaä¿¡æ¯
        meta_path = self.levels_dir / group_code / "meta.json"
        if not meta_path.exists():
            print(f"é”™è¯¯: è¯åº“ {group_code} ä¸å­˜åœ¨")
            return GroupValidation(
                group_code=group_code,
                group_name="æœªçŸ¥",
                total_levels=0,
                validated_levels=0,
                success_count=0,
                failed_count=0
            )
        
        with open(meta_path, "r", encoding="utf-8") as f:
            meta = json.load(f)
        
        group_name = meta.get("name", group_code)
        total_levels = meta.get("level_count", 0)
        
        if verbose:
            print(f"\néªŒè¯è¯åº“: {group_name} ({group_code})")
            print(f"æ€»å…³å¡æ•°: {total_levels}")
            print("-" * 50)
        
        result = GroupValidation(
            group_code=group_code,
            group_name=group_name,
            total_levels=total_levels,
            validated_levels=0,
            success_count=0,
            failed_count=0
        )
        
        # ç¡®å®šéªŒè¯èŒƒå›´
        max_level = min(total_levels, limit) if limit else total_levels
        
        for level in range(1, max_level + 1):
            level_result = self.validate_level(group_code, level)
            result.validated_levels += 1
            result.total_load_time_ms += level_result.load_time_ms
            result.total_solve_time_ms += level_result.solve_time_ms
            result.all_results.append(level_result)
            
            if level_result.status == ValidationStatus.SUCCESS:
                result.success_count += 1
                if verbose and level % 100 == 0:
                    print(f"  å·²éªŒè¯ {level}/{max_level} å…³...")
            else:
                result.failed_count += 1
                result.error_details.append(level_result)
                if verbose:
                    print(f"  âœ— å…³å¡ {level}: {level_result.status.value} - {', '.join(level_result.errors[:2])}")
        
        if verbose:
            print(f"\néªŒè¯å®Œæˆ: {result.success_count}/{result.validated_levels} é€šè¿‡")
            if result.failed_count > 0:
                print(f"å¤±è´¥å…³å¡: {result.failed_count}")
            print(f"æ€»åŠ è½½æ—¶é—´: {result.total_load_time_ms:.1f}ms")
            print(f"æ€»è§£ç­”æ—¶é—´: {result.total_solve_time_ms:.1f}ms")
            print(f"å¹³å‡æ¯å…³: {(result.total_load_time_ms + result.total_solve_time_ms) / max(result.validated_levels, 1):.2f}ms")
        
        return result
    
    def validate_all(self, limit: int = None, verbose: bool = True) -> Dict[str, GroupValidation]:
        """éªŒè¯æ‰€æœ‰è¯åº“"""
        results = {}
        
        # è·å–æ‰€æœ‰è¯åº“ç›®å½•
        group_dirs = [d for d in self.levels_dir.iterdir() if d.is_dir() and (d / "meta.json").exists()]
        
        if verbose:
            print("=" * 60)
            print("å¼€å§‹éªŒè¯æ‰€æœ‰è¯åº“")
            print(f"å…± {len(group_dirs)} ä¸ªè¯åº“")
            print("=" * 60)
        
        for group_dir in sorted(group_dirs):
            group_code = group_dir.name
            result = self.validate_group(group_code, limit=limit, verbose=verbose)
            results[group_code] = result
        
        return results
    
    def generate_report(self, results: Dict[str, GroupValidation], output_format: str = "json") -> Path:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if output_format == "json":
            report_path = self.reports_dir / f"validation_report_{timestamp}.json"
            
            report_data = {
                "generated_at": datetime.now().isoformat(),
                "summary": {
                    "total_groups": len(results),
                    "total_levels": sum(r.total_levels for r in results.values()),
                    "validated_levels": sum(r.validated_levels for r in results.values()),
                    "success_count": sum(r.success_count for r in results.values()),
                    "failed_count": sum(r.failed_count for r in results.values()),
                    "total_load_time_ms": sum(r.total_load_time_ms for r in results.values()),
                    "total_solve_time_ms": sum(r.total_solve_time_ms for r in results.values()),
                },
                "groups": []
            }
            
            for group_code, result in results.items():
                group_data = {
                    "group_code": group_code,
                    "group_name": result.group_name,
                    "total_levels": result.total_levels,
                    "validated_levels": result.validated_levels,
                    "success_count": result.success_count,
                    "failed_count": result.failed_count,
                    "success_rate": f"{result.success_count / max(result.validated_levels, 1) * 100:.1f}%",
                    "avg_load_time_ms": result.total_load_time_ms / max(result.validated_levels, 1),
                    "avg_solve_time_ms": result.total_solve_time_ms / max(result.validated_levels, 1),
                    "error_levels": [
                        {
                            "level": e.level,
                            "status": e.status.value,
                            "errors": e.errors,
                            "words": e.words
                        }
                        for e in result.error_details
                    ]
                }
                report_data["groups"].append(group_data)
            
            with open(report_path, "w", encoding="utf-8") as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        elif output_format == "html":
            report_path = self.reports_dir / f"validation_report_{timestamp}.html"
            html_content = self._generate_html_report(results)
            with open(report_path, "w", encoding="utf-8") as f:
                f.write(html_content)
        
        elif output_format == "csv":
            report_path = self.reports_dir / f"validation_report_{timestamp}.csv"
            csv_content = self._generate_csv_report(results)
            with open(report_path, "w", encoding="utf-8") as f:
                f.write(csv_content)
        
        else:
            # çº¯æ–‡æœ¬æ ¼å¼
            report_path = self.reports_dir / f"validation_report_{timestamp}.txt"
            text_content = self._generate_text_report(results)
            with open(report_path, "w", encoding="utf-8") as f:
                f.write(text_content)
        
        print(f"\næŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        return report_path
    
    def _generate_html_report(self, results: Dict[str, GroupValidation]) -> str:
        """ç”ŸæˆHTMLæ ¼å¼æŠ¥å‘Š"""
        total_levels = sum(r.validated_levels for r in results.values())
        total_success = sum(r.success_count for r in results.values())
        total_failed = sum(r.failed_count for r in results.values())
        
        html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å…³å¡éªŒè¯æŠ¥å‘Š</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; }}
        h1 {{ color: #333; }}
        .summary {{ background: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .summary h2 {{ margin-top: 0; }}
        .stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 15px; }}
        .stat-card {{ background: #e3f2fd; padding: 15px; border-radius: 6px; text-align: center; }}
        .stat-value {{ font-size: 24px; font-weight: bold; color: #1976d2; }}
        .stat-label {{ color: #666; font-size: 14px; }}
        .group-table {{ width: 100%; background: white; border-radius: 8px; overflow: hidden; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 20px; }}
        .group-table th, .group-table td {{ padding: 12px; text-align: left; border-bottom: 1px solid #eee; }}
        .group-table th {{ background: #1976d2; color: white; }}
        .group-table tr:hover {{ background: #f5f5f5; }}
        .success {{ color: #4caf50; }}
        .failed {{ color: #f44336; }}
        .error-details {{ background: #fff3e0; padding: 10px; border-radius: 4px; margin-top: 10px; font-size: 12px; }}
        .progress-bar {{ background: #e0e0e0; border-radius: 10px; height: 20px; overflow: hidden; }}
        .progress-fill {{ background: #4caf50; height: 100%; transition: width 0.3s; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ® å…³å¡éªŒè¯æŠ¥å‘Š</h1>
        <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        
        <div class="summary">
            <h2>ğŸ“Š æ€»ä½“ç»Ÿè®¡</h2>
            <div class="stats">
                <div class="stat-card">
                    <div class="stat-value">{len(results)}</div>
                    <div class="stat-label">è¯åº“æ•°é‡</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{total_levels}</div>
                    <div class="stat-label">éªŒè¯å…³å¡</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value success">{total_success}</div>
                    <div class="stat-label">é€šè¿‡</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value failed">{total_failed}</div>
                    <div class="stat-label">å¤±è´¥</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{total_success / max(total_levels, 1) * 100:.1f}%</div>
                    <div class="stat-label">é€šè¿‡ç‡</div>
                </div>
            </div>
        </div>
        
        <h2>ğŸ“š è¯åº“è¯¦æƒ…</h2>
        <table class="group-table">
            <thead>
                <tr>
                    <th>è¯åº“</th>
                    <th>å…³å¡æ•°</th>
                    <th>é€šè¿‡</th>
                    <th>å¤±è´¥</th>
                    <th>é€šè¿‡ç‡</th>
                    <th>å¹³å‡åŠ è½½(ms)</th>
                </tr>
            </thead>
            <tbody>"""
        
        for group_code, result in sorted(results.items(), key=lambda x: x[1].failed_count, reverse=True):
            success_rate = result.success_count / max(result.validated_levels, 1) * 100
            avg_load = result.total_load_time_ms / max(result.validated_levels, 1)
            
            html += f"""
                <tr>
                    <td><strong>{result.group_name}</strong> ({group_code})</td>
                    <td>{result.validated_levels}</td>
                    <td class="success">{result.success_count}</td>
                    <td class="failed">{result.failed_count}</td>
                    <td>
                        <div class="progress-bar">
                            <div class="progress-fill" style="width: {success_rate}%"></div>
                        </div>
                        {success_rate:.1f}%
                    </td>
                    <td>{avg_load:.2f}</td>
                </tr>"""
            
            if result.error_details:
                html += f"""
                <tr>
                    <td colspan="6">
                        <div class="error-details">
                            <strong>é”™è¯¯å…³å¡:</strong>
                            {', '.join([f'ç¬¬{e.level}å…³({e.status.value})' for e in result.error_details[:10]])}
                            {f'... å…±{len(result.error_details)}ä¸ª' if len(result.error_details) > 10 else ''}
                        </div>
                    </td>
                </tr>"""
        
        html += """
            </tbody>
        </table>
    </div>
</body>
</html>"""
        return html
    
    def _generate_text_report(self, results: Dict[str, GroupValidation]) -> str:
        """ç”Ÿæˆçº¯æ–‡æœ¬æŠ¥å‘Š"""
        lines = []
        lines.append("=" * 60)
        lines.append("å…³å¡éªŒè¯æŠ¥å‘Š")
        lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("=" * 60)
        
        total_levels = sum(r.validated_levels for r in results.values())
        total_success = sum(r.success_count for r in results.values())
        total_failed = sum(r.failed_count for r in results.values())
        
        lines.append(f"\næ€»ä½“ç»Ÿè®¡:")
        lines.append(f"  è¯åº“æ•°é‡: {len(results)}")
        lines.append(f"  éªŒè¯å…³å¡: {total_levels}")
        lines.append(f"  é€šè¿‡: {total_success}")
        lines.append(f"  å¤±è´¥: {total_failed}")
        lines.append(f"  é€šè¿‡ç‡: {total_success / max(total_levels, 1) * 100:.1f}%")
        
        lines.append("\n" + "-" * 60)
        lines.append("å„è¯åº“è¯¦æƒ…:")
        lines.append("-" * 60)
        
        for group_code, result in sorted(results.items()):
            success_rate = result.success_count / max(result.validated_levels, 1) * 100
            status = "âœ“" if result.failed_count == 0 else "âœ—"
            lines.append(f"\n{status} {result.group_name} ({group_code})")
            lines.append(f"  å…³å¡: {result.validated_levels}, é€šè¿‡: {result.success_count}, å¤±è´¥: {result.failed_count} ({success_rate:.1f}%)")
            
            if result.error_details:
                lines.append(f"  é”™è¯¯å…³å¡:")
                for e in result.error_details[:5]:
                    lines.append(f"    - ç¬¬{e.level}å…³: {e.status.value} - {', '.join(e.errors[:2])}")
                if len(result.error_details) > 5:
                    lines.append(f"    ... å…±{len(result.error_details)}ä¸ªé”™è¯¯å…³å¡")
        
        return "\n".join(lines)
    
    def _generate_csv_report(self, results: Dict[str, GroupValidation]) -> str:
        """ç”ŸæˆCSVæ ¼å¼æŠ¥å‘Š"""
        import csv
        import io
        
        output = io.StringIO()
        writer = csv.writer(output)
        
        # å†™å…¥æ ‡é¢˜è¡Œ
        writer.writerow([
            'è¯åº“ä»£ç ', 'è¯åº“åç§°', 'metaå…³å¡æ•°', 'å®é™…æ–‡ä»¶æ•°', 'ä¸€è‡´æ€§', 
            'éªŒè¯å…³å¡', 'é€šè¿‡æ•°', 'å¤±è´¥æ•°', 'é€šè¿‡ç‡', 
            'å¹³å‡åŠ è½½(ms)', 'å¹³å‡è§£ç­”(ms)', 'é”™è¯¯å…³å¡'
        ])
        
        for group_code, result in sorted(results.items()):
            success_rate = result.success_count / max(result.validated_levels, 1) * 100
            avg_load = result.total_load_time_ms / max(result.validated_levels, 1)
            avg_solve = result.total_solve_time_ms / max(result.validated_levels, 1)
            
            # ç»Ÿè®¡å®é™…æ–‡ä»¶æ•°
            actual_file_count = result.validated_levels
            consistency = "âœ“" if result.total_levels == actual_file_count else f"âœ— (å·®å¼‚:{result.total_levels - actual_file_count})"
            
            # é”™è¯¯å…³å¡åˆ—è¡¨
            error_levels = ', '.join([str(e.level) for e in result.error_details[:10]])
            if len(result.error_details) > 10:
                error_levels += f'...å…±{len(result.error_details)}ä¸ª'
            
            writer.writerow([
                group_code,
                result.group_name,
                result.total_levels,
                actual_file_count,
                consistency,
                result.validated_levels,
                result.success_count,
                result.failed_count,
                f"{success_rate:.1f}%",
                f"{avg_load:.2f}",
                f"{avg_solve:.2f}",
                error_levels or '-'
            ])
        
        # æ·»åŠ æ±‡æ€»è¡Œ
        total_levels = sum(r.validated_levels for r in results.values())
        total_success = sum(r.success_count for r in results.values())
        total_failed = sum(r.failed_count for r in results.values())
        total_meta = sum(r.total_levels for r in results.values())
        total_load = sum(r.total_load_time_ms for r in results.values())
        total_solve = sum(r.total_solve_time_ms for r in results.values())
        
        writer.writerow([])
        writer.writerow([
            'æ±‡æ€»', '-', total_meta, total_levels, 
            "âœ“" if total_meta == total_levels else "âœ—",
            total_levels, total_success, total_failed,
            f"{total_success / max(total_levels, 1) * 100:.1f}%",
            f"{total_load / max(total_levels, 1):.2f}",
            f"{total_solve / max(total_levels, 1):.2f}",
            '-'
        ])
        
        return output.getvalue()
    
    def check_file_consistency(self, group_code: str) -> Tuple[int, int, bool]:
        """æ£€æŸ¥å…³å¡æ–‡ä»¶æ•°é‡ä¸meta.jsonçš„ä¸€è‡´æ€§
        
        Returns:
            (meta_count, actual_count, is_consistent)
        """
        meta_path = self.levels_dir / group_code / "meta.json"
        if not meta_path.exists():
            return 0, 0, False
        
        with open(meta_path, "r", encoding="utf-8") as f:
            meta = json.load(f)
        
        meta_count = meta.get("level_count", 0)
        
        # ç»Ÿè®¡å®é™…å…³å¡æ–‡ä»¶æ•°é‡
        group_dir = self.levels_dir / group_code
        actual_count = len([f for f in group_dir.iterdir() if f.suffix == '.json' and f.name != 'meta.json'])
        
        return meta_count, actual_count, meta_count == actual_count


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='å…³å¡éªŒè¯å·¥å…·')
    parser.add_argument('--group', '-g', type=str, action='append', help='æŒ‡å®šéªŒè¯çš„è¯åº“ï¼ˆå¯å¤šæ¬¡ä½¿ç”¨ï¼‰')
    parser.add_argument('--all', '-a', action='store_true', help='éªŒè¯æ‰€æœ‰è¯åº“')
    parser.add_argument('--limit', '-l', type=int, help='æ¯ä¸ªè¯åº“åªéªŒè¯å‰Nå…³')
    parser.add_argument('--report', '-r', choices=['json', 'html', 'text', 'csv'], default='json', help='æŠ¥å‘Šæ ¼å¼')
    parser.add_argument('--quiet', '-q', action='store_true', help='å®‰é™æ¨¡å¼ï¼Œåªè¾“å‡ºç»“æœ')
    
    args = parser.parse_args()
    
    validator = LevelValidator()
    
    if args.all:
        results = validator.validate_all(limit=args.limit, verbose=not args.quiet)
    elif args.group:
        results = {}
        for group in args.group:
            result = validator.validate_group(group, limit=args.limit, verbose=not args.quiet)
            results[group] = result
    else:
        # é»˜è®¤éªŒè¯æ‰€æœ‰
        results = validator.validate_all(limit=args.limit, verbose=not args.quiet)
    
    # ç”ŸæˆæŠ¥å‘Š
    if results:
        report_path = validator.generate_report(results, output_format=args.report)
        
        # æ‰“å°ç®€è¦ç»Ÿè®¡
        print("\n" + "=" * 60)
        print("éªŒè¯å®Œæˆç»Ÿè®¡")
        print("=" * 60)
        
        total_levels = sum(r.validated_levels for r in results.values())
        total_success = sum(r.success_count for r in results.values())
        total_failed = sum(r.failed_count for r in results.values())
        
        print(f"æ€»è¯åº“: {len(results)}")
        print(f"æ€»å…³å¡: {total_levels}")
        print(f"é€šè¿‡: {total_success}")
        print(f"å¤±è´¥: {total_failed}")
        print(f"é€šè¿‡ç‡: {total_success / max(total_levels, 1) * 100:.1f}%")
        
        if total_failed > 0:
            print(f"\nå¤±è´¥å…³å¡è¯¦æƒ…è¯·æŸ¥çœ‹æŠ¥å‘Š: {report_path}")


if __name__ == "__main__":
    main()
