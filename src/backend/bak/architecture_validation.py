#!/usr/bin/env python3
"""
æ¶æ„å¯è¡Œæ€§éªŒè¯ç®—æ³•
===================

éªŒè¯ã€Šæˆ‘çˆ±å¡«å•è¯ã€‹æ¸¸æˆæ¶æ„çš„æ ¸å¿ƒæœºåˆ¶å¯è¡Œæ€§ï¼š
1. åŒå¼•æ“ç­–ç•¥éªŒè¯ - ç¨€ç–å¸ƒå±€ vs å¯†é›†å¸ƒå±€
2. è¯åº“è¦†ç›–åº¦éªŒè¯ - å„éš¾åº¦è¯åº“èƒ½å¦ç”Ÿæˆè¶³å¤Ÿçš„è°œé¢˜
3. æ€§èƒ½åŸºå‡†æµ‹è¯• - å“åº”æ—¶é—´æ˜¯å¦æ»¡è¶³é¢„ç®—
4. CSPç®—æ³•æ”¶æ•›æ€§ - çº¦æŸæ»¡è¶³é—®é¢˜æ˜¯å¦å¯è§£

ä½œè€…: Cloud Dragonborn (Game Architect)
æ—¥æœŸ: 2026-01-24
"""

import sys
import json
import time
import statistics
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Dict, Tuple, Optional
from collections import defaultdict

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from puzzle_generator import CrosswordGenerator, PROGRESSIVE_LEVEL_CONFIG
from csp_puzzle_generator import CSPPuzzleGenerator, WordIndex
from vocabulary import VocabularyManager


# ==================== æ•°æ®ç»“æ„å®šä¹‰ ====================

@dataclass
class ValidationResult:
    """éªŒè¯ç»“æœ"""
    test_name: str
    passed: bool
    score: float  # 0-100
    details: Dict = field(default_factory=dict)
    message: str = ""


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    mean_ms: float
    p50_ms: float
    p95_ms: float
    p99_ms: float
    min_ms: float
    max_ms: float
    

# ==================== éªŒè¯å™¨ç±» ====================

class ArchitectureValidator:
    """æ¶æ„éªŒè¯å™¨ - éªŒè¯æ ¸å¿ƒæœºåˆ¶çš„å¯è¡Œæ€§"""
    
    # æ€§èƒ½é¢„ç®— (æ¯«ç§’)
    PERFORMANCE_BUDGET = {
        "puzzle_generation": {"mean": 500, "p95": 1000, "p99": 2000},
        "answer_verification": {"mean": 10, "p95": 50, "p99": 100},
    }
    
    # æˆåŠŸç‡é˜ˆå€¼
    SUCCESS_RATE_THRESHOLD = {
        "sparse": 0.85,    # ç¨€ç–å¸ƒå±€è‡³å°‘85%æˆåŠŸç‡
        "dense": 0.70,     # å¯†é›†å¸ƒå±€è‡³å°‘70%æˆåŠŸç‡
    }
    
    def __init__(self):
        self.vocab_manager = VocabularyManager()
        self.sparse_generator = CrosswordGenerator()
        self.dense_generator = CSPPuzzleGenerator()
        
        self.results: List[ValidationResult] = []
        
    def run_all_validations(self) -> Dict:
        """è¿è¡Œæ‰€æœ‰éªŒè¯æµ‹è¯•"""
        print("=" * 70)
        print("ğŸ›ï¸  æ¶æ„å¯è¡Œæ€§éªŒè¯ - Cloud Dragonborn")
        print("=" * 70)
        print()
        
        # 1. è¯åº“éªŒè¯
        self._validate_vocabulary_coverage()
        
        # 2. ç¨€ç–å¸ƒå±€å¼•æ“éªŒè¯
        self._validate_sparse_engine()
        
        # 3. å¯†é›†å¸ƒå±€å¼•æ“éªŒè¯
        self._validate_dense_engine()
        
        # 4. åŒå¼•æ“ååŒéªŒè¯
        self._validate_dual_engine_strategy()
        
        # 5. æ€§èƒ½åŸºå‡†æµ‹è¯•
        self._validate_performance()
        
        # 6. CSPç®—æ³•æ”¶æ•›æ€§éªŒè¯
        self._validate_csp_convergence()
        
        # æ±‡æ€»æŠ¥å‘Š
        return self._generate_report()
    
    def _validate_vocabulary_coverage(self):
        """éªŒè¯è¯åº“è¦†ç›–åº¦"""
        print("\nğŸ“š è¯åº“è¦†ç›–åº¦éªŒè¯")
        print("-" * 50)
        
        groups = ["primary", "cet4", "cet6", "ielts", "gre"]
        grid_sizes = [5, 6, 7, 8, 10]
        
        coverage_matrix = {}
        
        for group in groups:
            coverage_matrix[group] = {}
            words = self.vocab_manager.get_words(group, limit=10000)
            
            if not words:
                print(f"  âš ï¸  {group}: è¯åº“ä¸ºç©ºæˆ–ä¸å­˜åœ¨")
                continue
            
            total = len(words)
            print(f"\n  ğŸ“– {group}: æ€»è¯æ±‡ {total}")
            
            # æŒ‰é•¿åº¦ç»Ÿè®¡
            length_dist = defaultdict(int)
            for w in words:
                length_dist[len(w["word"])] += 1
            
            for size in grid_sizes:
                count = length_dist.get(size, 0)
                coverage_matrix[group][size] = count
                status = "âœ“" if count >= 20 else "âš ï¸" if count >= 10 else "âœ—"
                print(f"      {size}å­—æ¯: {count:4d}ä¸ª {status}")
        
        # è®¡ç®—å¾—åˆ†
        score = 0
        checks = 0
        for group in groups:
            if group in coverage_matrix:
                for size in grid_sizes:
                    checks += 1
                    count = coverage_matrix.get(group, {}).get(size, 0)
                    if count >= 20:
                        score += 1
                    elif count >= 10:
                        score += 0.5
        
        final_score = (score / checks * 100) if checks > 0 else 0
        passed = final_score >= 60
        
        self.results.append(ValidationResult(
            test_name="è¯åº“è¦†ç›–åº¦",
            passed=passed,
            score=final_score,
            details={"coverage_matrix": coverage_matrix},
            message=f"å„è¯åº“åœ¨ç›®æ ‡é•¿åº¦ä¸Šçš„è¦†ç›–æƒ…å†µ"
        ))
        
        print(f"\n  å¾—åˆ†: {final_score:.1f}/100 {'âœ“ PASS' if passed else 'âœ— FAIL'}")
    
    def _validate_sparse_engine(self):
        """éªŒè¯ç¨€ç–å¸ƒå±€å¼•æ“"""
        print("\n\nğŸ”§ ç¨€ç–å¸ƒå±€å¼•æ“éªŒè¯ (CrosswordGenerator)")
        print("-" * 50)
        
        test_cases = [
            {"level": 1, "group": "primary", "expected_words": 2},
            {"level": 5, "group": "cet4", "expected_words": 3},
            {"level": 10, "group": "cet4", "expected_words": 4},
            {"level": 50, "group": "cet6", "expected_words": 4},
        ]
        
        successes = 0
        total = 0
        
        for case in test_cases:
            level = case["level"]
            group = case["group"]
            expected = case["expected_words"]
            
            # å¤šæ¬¡å°è¯•
            case_success = 0
            attempts = 5
            
            for _ in range(attempts):
                total += 1
                try:
                    puzzle = self.sparse_generator.generate_campaign_level(
                        level, group, self.vocab_manager
                    )
                    word_count = len(puzzle.get("words", []))
                    if word_count >= expected:
                        successes += 1
                        case_success += 1
                except Exception as e:
                    pass
            
            rate = case_success / attempts * 100
            status = "âœ“" if rate >= 80 else "âš ï¸" if rate >= 50 else "âœ—"
            print(f"  {status} Level {level:3d}, {group:8s}: {rate:.0f}% æˆåŠŸç‡")
        
        success_rate = successes / total if total > 0 else 0
        passed = success_rate >= self.SUCCESS_RATE_THRESHOLD["sparse"]
        score = success_rate * 100
        
        self.results.append(ValidationResult(
            test_name="ç¨€ç–å¸ƒå±€å¼•æ“",
            passed=passed,
            score=score,
            details={"success_rate": success_rate, "total_tests": total},
            message=f"æˆåŠŸç‡ {success_rate*100:.1f}%, é˜ˆå€¼ {self.SUCCESS_RATE_THRESHOLD['sparse']*100}%"
        ))
        
        print(f"\n  æ€»æˆåŠŸç‡: {success_rate*100:.1f}% {'âœ“ PASS' if passed else 'âœ— FAIL'}")
    
    def _validate_dense_engine(self):
        """éªŒè¯å¯†é›†å¸ƒå±€å¼•æ“ (CSP)"""
        print("\n\nğŸ”§ å¯†é›†å¸ƒå±€å¼•æ“éªŒè¯ (CSPPuzzleGenerator)")
        print("-" * 50)
        
        test_configs = [
            {"grid_size": 6, "group": "cet4", "name": "6x6 Easy"},
            {"grid_size": 7, "group": "cet4", "name": "7x7 Medium"},
            {"grid_size": 8, "group": "cet6", "name": "8x8 Hard"},
        ]
        
        successes = 0
        total = 0
        
        for config in test_configs:
            grid_size = config["grid_size"]
            group = config["group"]
            name = config["name"]
            
            # è·å–è¯åº“
            words = self.vocab_manager.get_words(group, limit=5000)
            
            case_success = 0
            attempts = 5
            
            for _ in range(attempts):
                total += 1
                try:
                    puzzle = self.dense_generator.generate_template_puzzle(
                        grid_size, words, timeout=3.0, max_retries=5
                    )
                    # æˆåŠŸæ¡ä»¶ï¼šç”Ÿæˆäº†è°œé¢˜ä¸”è‡³å°‘æœ‰2ä¸ªè¯ï¼ˆç®€åŒ–æ¨¡æ¿å¯èƒ½åªæœ‰3ä¸ªè¯ï¼‰
                    if puzzle and len(puzzle.row_words) + len(puzzle.col_words) >= 2:
                        successes += 1
                        case_success += 1
                except Exception as e:
                    pass
            
            rate = case_success / attempts * 100
            status = "âœ“" if rate >= 60 else "âš ï¸" if rate >= 40 else "âœ—"
            print(f"  {status} {name:12s}: {rate:.0f}% æˆåŠŸç‡")
        
        success_rate = successes / total if total > 0 else 0
        passed = success_rate >= self.SUCCESS_RATE_THRESHOLD["dense"]
        score = success_rate * 100
        
        self.results.append(ValidationResult(
            test_name="å¯†é›†å¸ƒå±€å¼•æ“",
            passed=passed,
            score=score,
            details={"success_rate": success_rate},
            message=f"æˆåŠŸç‡ {success_rate*100:.1f}%, é˜ˆå€¼ {self.SUCCESS_RATE_THRESHOLD['dense']*100}%"
        ))
        
        print(f"\n  æ€»æˆåŠŸç‡: {success_rate*100:.1f}% {'âœ“ PASS' if passed else 'âœ— FAIL'}")
    
    def _validate_dual_engine_strategy(self):
        """éªŒè¯åŒå¼•æ“ååŒç­–ç•¥"""
        print("\n\nğŸ”§ åŒå¼•æ“ååŒç­–ç•¥éªŒè¯")
        print("-" * 50)
        
        # æ¨¡æ‹Ÿå…³å¡1-50çš„ç”Ÿæˆ
        level_results = []
        
        for level in range(1, 51, 5):  # é‡‡æ ·æµ‹è¯•
            group = "cet4"
            
            # æ ¹æ®å…³å¡é€‰æ‹©å¼•æ“
            if level <= 30:
                engine = "sparse"
                try:
                    puzzle = self.sparse_generator.generate_campaign_level(
                        level, group, self.vocab_manager
                    )
                    success = len(puzzle.get("words", [])) >= 2
                except:
                    success = False
            else:
                engine = "dense"
                words = self.vocab_manager.get_words(group, limit=5000)
                grid_size = 6 if level <= 40 else 7
                try:
                    puzzle = self.dense_generator.generate_template_puzzle(
                        grid_size, words, timeout=2.0, max_retries=3
                    )
                    success = puzzle is not None
                except:
                    success = False
            
            level_results.append({
                "level": level,
                "engine": engine,
                "success": success
            })
            
            status = "âœ“" if success else "âœ—"
            print(f"  {status} Level {level:3d} â†’ {engine:6s} engine")
        
        success_count = sum(1 for r in level_results if r["success"])
        success_rate = success_count / len(level_results)
        passed = success_rate >= 0.8
        score = success_rate * 100
        
        self.results.append(ValidationResult(
            test_name="åŒå¼•æ“ååŒ",
            passed=passed,
            score=score,
            details={"level_results": level_results},
            message=f"å…³å¡è¦†ç›–ç‡ {success_rate*100:.1f}%"
        ))
        
        print(f"\n  è¦†ç›–ç‡: {success_rate*100:.1f}% {'âœ“ PASS' if passed else 'âœ— FAIL'}")
    
    def _validate_performance(self):
        """éªŒè¯æ€§èƒ½æ˜¯å¦æ»¡è¶³é¢„ç®—"""
        print("\n\nâ±ï¸  æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("-" * 50)
        
        # æµ‹è¯•è°œé¢˜ç”Ÿæˆæ€§èƒ½
        print("\n  ğŸ§© è°œé¢˜ç”Ÿæˆæ€§èƒ½:")
        gen_times = []
        
        for _ in range(20):
            start = time.time()
            try:
                puzzle = self.sparse_generator.generate_campaign_level(
                    5, "cet4", self.vocab_manager
                )
                elapsed = (time.time() - start) * 1000
                gen_times.append(elapsed)
            except:
                pass
        
        if gen_times:
            metrics = self._calculate_metrics(gen_times)
            budget = self.PERFORMANCE_BUDGET["puzzle_generation"]
            
            print(f"      Mean:  {metrics.mean_ms:6.1f}ms (é¢„ç®—: {budget['mean']}ms)")
            print(f"      P50:   {metrics.p50_ms:6.1f}ms")
            print(f"      P95:   {metrics.p95_ms:6.1f}ms (é¢„ç®—: {budget['p95']}ms)")
            print(f"      P99:   {metrics.p99_ms:6.1f}ms (é¢„ç®—: {budget['p99']}ms)")
            
            gen_passed = metrics.p95_ms <= budget["p95"]
        else:
            gen_passed = False
            metrics = None
        
        # æµ‹è¯•ç­”æ¡ˆéªŒè¯æ€§èƒ½
        print("\n  âœ“ ç­”æ¡ˆéªŒè¯æ€§èƒ½:")
        verify_times = []
        
        # å…ˆç”Ÿæˆä¸€ä¸ªè°œé¢˜è·å–word_id
        puzzle = self.sparse_generator.generate_campaign_level(1, "cet4", self.vocab_manager)
        if puzzle and puzzle.get("words"):
            word = puzzle["words"][0]
            word_id = word["id"]
            correct_answer = word["word"]
            
            for _ in range(100):
                start = time.time()
                result = self.sparse_generator.verify_answer(word_id, correct_answer)
                elapsed = (time.time() - start) * 1000
                verify_times.append(elapsed)
        
        if verify_times:
            v_metrics = self._calculate_metrics(verify_times)
            v_budget = self.PERFORMANCE_BUDGET["answer_verification"]
            
            print(f"      Mean:  {v_metrics.mean_ms:6.3f}ms (é¢„ç®—: {v_budget['mean']}ms)")
            print(f"      P95:   {v_metrics.p95_ms:6.3f}ms (é¢„ç®—: {v_budget['p95']}ms)")
            
            verify_passed = v_metrics.p95_ms <= v_budget["p95"]
        else:
            verify_passed = False
            v_metrics = None
        
        overall_passed = gen_passed and verify_passed
        score = (50 if gen_passed else 0) + (50 if verify_passed else 0)
        
        self.results.append(ValidationResult(
            test_name="æ€§èƒ½åŸºå‡†",
            passed=overall_passed,
            score=score,
            details={
                "generation": metrics.__dict__ if metrics else {},
                "verification": v_metrics.__dict__ if v_metrics else {}
            },
            message=f"ç”ŸæˆP95: {metrics.p95_ms:.1f}ms" if metrics else "æµ‹è¯•å¤±è´¥"
        ))
        
        print(f"\n  ç»“æœ: {'âœ“ PASS' if overall_passed else 'âœ— FAIL'}")
    
    def _validate_csp_convergence(self):
        """éªŒè¯CSPç®—æ³•æ”¶æ•›æ€§"""
        print("\n\nğŸ§® CSPç®—æ³•æ”¶æ•›æ€§éªŒè¯")
        print("-" * 50)
        
        # æµ‹è¯•ä¸åŒè§„æ¨¡çš„CSPé—®é¢˜
        test_sizes = [6, 7, 8]
        convergence_results = []
        
        words = self.vocab_manager.get_words("cet4", limit=5000)
        
        for size in test_sizes:
            successes = 0
            total_time = 0
            attempts = 10
            backtracks_sum = 0
            
            for _ in range(attempts):
                start = time.time()
                try:
                    puzzle = self.dense_generator.generate_template_puzzle(
                        size, words, timeout=3.0, max_retries=3
                    )
                    if puzzle:
                        successes += 1
                except:
                    pass
                total_time += time.time() - start
            
            avg_time = total_time / attempts * 1000
            rate = successes / attempts * 100
            
            convergence_results.append({
                "size": size,
                "success_rate": rate,
                "avg_time_ms": avg_time
            })
            
            status = "âœ“" if rate >= 60 else "âš ï¸" if rate >= 40 else "âœ—"
            print(f"  {status} {size}x{size}: æˆåŠŸç‡ {rate:.0f}%, å¹³å‡è€—æ—¶ {avg_time:.0f}ms")
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        avg_rate = sum(r["success_rate"] for r in convergence_results) / len(convergence_results)
        passed = avg_rate >= 50
        score = avg_rate
        
        self.results.append(ValidationResult(
            test_name="CSPæ”¶æ•›æ€§",
            passed=passed,
            score=score,
            details={"convergence_results": convergence_results},
            message=f"å¹³å‡æ”¶æ•›ç‡ {avg_rate:.1f}%"
        ))
        
        print(f"\n  å¹³å‡æ”¶æ•›ç‡: {avg_rate:.1f}% {'âœ“ PASS' if passed else 'âœ— FAIL'}")
    
    def _calculate_metrics(self, times: List[float]) -> PerformanceMetrics:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        sorted_times = sorted(times)
        n = len(sorted_times)
        
        return PerformanceMetrics(
            mean_ms=statistics.mean(sorted_times),
            p50_ms=sorted_times[int(n * 0.5)],
            p95_ms=sorted_times[int(n * 0.95)] if n >= 20 else sorted_times[-1],
            p99_ms=sorted_times[int(n * 0.99)] if n >= 100 else sorted_times[-1],
            min_ms=sorted_times[0],
            max_ms=sorted_times[-1]
        )
    
    def _generate_report(self) -> Dict:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("\n")
        print("=" * 70)
        print("ğŸ“Š æ¶æ„å¯è¡Œæ€§éªŒè¯æŠ¥å‘Š")
        print("=" * 70)
        
        total_score = 0
        passed_count = 0
        
        print("\næµ‹è¯•ç»“æœæ±‡æ€»:")
        print("-" * 50)
        
        for result in self.results:
            status = "âœ“ PASS" if result.passed else "âœ— FAIL"
            print(f"  {result.test_name:20s}: {result.score:5.1f}/100  {status}")
            total_score += result.score
            if result.passed:
                passed_count += 1
        
        avg_score = total_score / len(self.results) if self.results else 0
        all_passed = passed_count == len(self.results)
        
        print("-" * 50)
        print(f"  {'æ€»ä½“è¯„åˆ†':20s}: {avg_score:5.1f}/100")
        print(f"  {'é€šè¿‡æµ‹è¯•':20s}: {passed_count}/{len(self.results)}")
        
        print("\n" + "=" * 70)
        if all_passed:
            print("ğŸ‰ ç»“è®º: æ¶æ„è®¾è®¡å¯è¡Œ! æ‰€æœ‰æ ¸å¿ƒæœºåˆ¶éªŒè¯é€šè¿‡ã€‚")
        elif avg_score >= 70:
            print("âš ï¸  ç»“è®º: æ¶æ„åŸºæœ¬å¯è¡Œï¼Œéƒ¨åˆ†æœºåˆ¶éœ€è¦ä¼˜åŒ–ã€‚")
        else:
            print("âŒ ç»“è®º: æ¶æ„å­˜åœ¨é£é™©ï¼Œéœ€è¦é‡æ–°è¯„ä¼°å…³é”®ç»„ä»¶ã€‚")
        print("=" * 70)
        
        # å»ºè®®
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for result in self.results:
            if not result.passed:
                print(f"  - {result.test_name}: {result.message}")
        
        return {
            "overall_score": avg_score,
            "all_passed": all_passed,
            "passed_count": passed_count,
            "total_tests": len(self.results),
            "results": [
                {
                    "name": r.test_name,
                    "passed": r.passed,
                    "score": r.score,
                    "message": r.message
                }
                for r in self.results
            ]
        }


# ==================== ä¸»å‡½æ•° ====================

def main():
    """è¿è¡Œæ¶æ„éªŒè¯"""
    validator = ArchitectureValidator()
    report = validator.run_all_validations()
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = Path(__file__).parent.parent.parent / "_bmad-output" / "architecture-validation-report.json"
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    # è¿”å›é€€å‡ºç 
    return 0 if report["all_passed"] else 1


if __name__ == "__main__":
    exit(main())
